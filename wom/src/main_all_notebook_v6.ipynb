{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41220fd7-30fb-4aba-9343-0c839fd75e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import yaml\n",
    "import json\n",
    "import ast\n",
    "import praw\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from textwrap import dedent\n",
    "from reddit_helper import *    \n",
    "\n",
    "from langchain.llms import OpenAI, Ollama\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90c4f07a-7d2b-468f-b1cf-387cf8917d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_file_path = 'api_keys.json'\n",
    "with open(api_file_path, 'r') as file:\n",
    "    api_keys = json.load(file)        \n",
    "openai_gpt35 = ChatOpenAI(model_name=\"gpt-3.5-turbo\", \n",
    "                                temperature=0.7,\n",
    "                                openai_api_key=api_keys['openai'])\n",
    "openai_gpt4 = ChatOpenAI(model_name=\"gpt-4\", \n",
    "                                temperature=0.7,\n",
    "                                openai_api_key=api_keys['openai'])        \n",
    "llama31_8b = Ollama(model='llama3.1:8b',)\n",
    "gemma2_9b = Ollama(model='gemma2:9b',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae8feb0c-dd0f-4e74-b926-bfefcb3aebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_file_path = 'casaai_config.yaml'\n",
    "agent_cfg_path = 'agents.yaml'\n",
    "task_cfg_path = 'tasks.yaml'\n",
    "\n",
    "with open(cfg_file_path, 'r') as yaml_file:\n",
    "    cfg = yaml.safe_load(yaml_file)\n",
    "product_long = cfg.get('product_long_description', '')      \n",
    "product_short = cfg.get('product_short_description', '')\n",
    "product_name = cfg.get('product_short_description', '')\n",
    "domain = cfg.get('domain')\n",
    "broad_keywords = cfg.get('broad_keywords', [])\n",
    "output_format_1 = cfg.get('output_format_1')\n",
    "\n",
    "with open(agent_cfg_path, 'r') as yaml_file:\n",
    "    agent_cfg_data = yaml.safe_load(yaml_file)\n",
    "\n",
    "with open(task_cfg_path, 'r') as yaml_file:\n",
    "    task_cfg_data = yaml.safe_load(yaml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc6b60a8-0e4c-47b9-a1b4-277a99de1b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tip_text = \"If you do your BEST WORK, I'll give you a $100 commission!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe2fe8f2-c241-411d-b1d9-e1d3f9e5d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_decision_string(input_string):\n",
    "\n",
    "    pattern = r\"'comment_id':\\s*'([^']*)',\\s*'decision':\\s*(\\d+)\"\n",
    "\n",
    "    # Use re.findall to extract the values\n",
    "    matches = re.findall(pattern, input_string)\n",
    "\n",
    "    if matches:\n",
    "        comment_id, decision = matches[0]\n",
    "    else:\n",
    "        comment_id = \"na\"\n",
    "        decision = \"discard\"\n",
    "\n",
    "    if \"justification\" in input_string:\n",
    "        justification = input_string.split(\"justification\")[-1]\n",
    "    else:\n",
    "        justification = \"Not available\"\n",
    "    \n",
    "    return comment_id, decision, justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "168f123a-cbb1-484b-9b1e-ef101a8c9d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_score_string(input_string):\n",
    "\n",
    "    pattern = r\"'comment_id':\\s*'([^']*)',\\s*'score':\\s*(\\d+)\"\n",
    "\n",
    "    # Use re.findall to extract the values\n",
    "    matches = re.findall(pattern, input_string)\n",
    "\n",
    "    if matches:\n",
    "        comment_id, score = matches[0]\n",
    "    else:\n",
    "        comment_id = \"na\"\n",
    "        score = 0\n",
    "\n",
    "    if \"justification\" in input_string:\n",
    "        justification = input_string.split(\"justification\")[-1]\n",
    "    else:\n",
    "        justification = \"Not available\"\n",
    "    \n",
    "    return comment_id, score, justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d38bee08-0dda-40fb-886f-6edfb815d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calendar_date(unix_timestamp):\n",
    "    date_obj = datetime.utcfromtimestamp(unix_timestamp)\n",
    "    readable_date = date_obj.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return readable_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "81f838b3-97de-4b2c-9aa8-5e7720b5cf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_decision_output(decision_lst, old_comments):\n",
    "    decision_analysis_lst = []\n",
    "    decision_bad_list = []\n",
    "    tot_comments = 0\n",
    "    bad_cnt = 0\n",
    "    decision_relevant_json_list = []\n",
    "    decision_discarded_json_list = []\n",
    "    for item in decision_lst:  \n",
    "        sep = \"^\"\n",
    "        for comment in item:\n",
    "            tot_comments += 1\n",
    "            try:\n",
    "                comm_key = list(comment.keys())[0]\n",
    "                comm_id  = comment[comm_key].strip()\n",
    "                if comm_id in comment_dict_list:                 \n",
    "                    parent_id = comment_dict[comm_id][\"parent_id\"]\n",
    "                    if parent_id is None:\n",
    "                        parent_id = 'NA'\n",
    "                    decision = comment['decision']\n",
    "                    justify  = comment[\"justification\"]\n",
    "                    comment_text = comment_dict[comm_id][\"text\"]\n",
    "                    text_str = sep + comm_id + sep + parent_id + sep + decision + sep + justify + sep + comment_text + sep\n",
    "                    if comment['decision'] == 'relevant':\n",
    "                        decision_relevant_json_list.append(comment)\n",
    "                    else:\n",
    "                        decision_discarded_json_list.append(comment)\n",
    "                    decision_analysis_lst.append(text_str)            \n",
    "                else: \n",
    "                    print(f'Comment ID not found : {comm_id}')\n",
    "                    bad_cnt += 1\n",
    "                    decision_bad_list.append(comm_id)\n",
    "            except:\n",
    "                print(f'comment key error : {comment}')\n",
    "                bad_cnt += 1\n",
    "    print(f'relevant : {len(decision_relevant_json_list)} discarded : {len(decision_discarded_json_list)} bad_cnt: {bad_cnt} total: {tot_comments}')\n",
    "    \n",
    "    old_comment_list = []\n",
    "    for comment in old_comments:  \n",
    "        sep = \"^\"\n",
    "        comm_id  = comment[\"comment_id\"]\n",
    "        parent_id = comment[\"parent_id\"]\n",
    "        comment_text  = comment[\"text\"]\n",
    "        created_date = get_calendar_date(comment['created_utc'])\n",
    "        age = str(comment[\"age\"])\n",
    "        text_str = sep + comm_id + sep + parent_id + sep + age + sep + created_date + sep + comment_text + sep\n",
    "        old_comment_list.append(text_str)      \n",
    "    print(f'Old comments already filtered out : {len(old_comments)}')\n",
    "    \n",
    "    output = (decision_relevant_json_list, decision_discarded_json_list, decision_analysis_lst, old_comment_list)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "84a93777-5f89-40d7-9932-b2a17a66f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_score_output(score_result_lst):\n",
    "    analysis_lst = []\n",
    "    bad_list = []\n",
    "    tot_comments = 0\n",
    "    bad_cnt = 0\n",
    "    good_json_list = []\n",
    "    sep = \"^\"\n",
    "    for comment in score_result_lst:\n",
    "        tot_comments += 1\n",
    "        try:\n",
    "            comm_key = list(comment.keys())[0]\n",
    "            comm_id  = comment[comm_key].strip()\n",
    "            \n",
    "            if comm_id in comment_dict_list:  \n",
    "                parent_id = comment_dict[comm_id][\"parent_id\"]\n",
    "                if parent_id is None:\n",
    "                    parent_id = 'NA'\n",
    "                score = comment['score']\n",
    "                age = comment_dict[comm_id][\"age\"]\n",
    "                created = comment_dict[comm_id][\"created\"]\n",
    "                justify  = comment[\"justification\"]\n",
    "                comment_text = comment_dict[comm_id][\"text\"]\n",
    "                text_str = sep + comm_id + sep + parent_id + sep + str(score) + sep + str(age) + sep + created + sep + justify \\\n",
    "                            + sep + comment_text + sep\n",
    "                analysis_lst.append(text_str) \n",
    "                good_json_list.append(comm_id)\n",
    "            else: \n",
    "                print(f'Comment ID not found : {comm_id}')\n",
    "                bad_cnt += 1\n",
    "                bad_list.append(comm_id)\n",
    "        except:\n",
    "            print(f'comment key error : {comment}')\n",
    "            bad_cnt += 1\n",
    "    print(f'relevant : {len(good_json_list)} bad_cnt: {bad_cnt} total: {tot_comments}')\n",
    "    output = (good_json_list, bad_list, analysis_lst)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfb8901b-116f-4751-b5f0-b4cb43bea515",
   "metadata": {},
   "outputs": [],
   "source": [
    "backstory = agent_cfg_data['content_filter_analyst']['backstory'] \n",
    "goal = agent_cfg_data['content_filter_analyst']['goal']\n",
    "role = agent_cfg_data['content_filter_analyst']['role'] \n",
    "content_filter_analyst = Agent(\n",
    "                            role=role,\n",
    "                            goal=goal,\n",
    "                            backstory=backstory,\n",
    "                            allow_delegation=False,\n",
    "                            verbose=False,\n",
    "                            llm=gemma2_9b,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "affe0ea5-4b89-4577-968a-87ce473a5622",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionOutput(BaseModel):\n",
    "    comment_id: str\n",
    "    decision: str\n",
    "    justification: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "346f7d77-e2b1-402b-8ecb-c43be309916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = task_cfg_data['content_filter_task']['description']\n",
    "expected_out = task_cfg_data['content_filter_task']['expected_out'] \n",
    "        \n",
    "content_filter_task = Task(\n",
    "                            description=description,\n",
    "                            expected_output=expected_out,\n",
    "                            output_json=DecisionOutput,\n",
    "                            agent=content_filter_analyst,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ddfa1db5-dcd0-4de7-9d47-19b9a1d06ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 08:13:45,936 - 140270313555776 - __init__.py-__init__:538 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "response_creation_crew = Crew(\n",
    "    agents=[content_filter_analyst,],\n",
    "    tasks=[content_filter_task,],\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "354f401e-8949-4f13-b217-0ba25d573984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post_cnt: 0 + 19 = 19\n",
      "comm_cnt: 0 + 692 = 692\n",
      "cond_cnt: 711 = 19 + 692\n",
      "Cross_ck: 19 = 19\n"
     ]
    }
   ],
   "source": [
    "reddit_posts, reddit_post_ids = fetch_reddit_test()\n",
    "condensed_reddit_data, unique_post_ids, unique_comment_ids = condense_data(reddit_posts, reddit_post_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6d68feb5-a9f7-4f8e-993c-d0e0f6a49174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 169\n",
      "1 : 108\n",
      "2 : 31\n",
      "3 : 57\n",
      "4 : 0\n",
      "5 : 33\n",
      "6 : 60\n",
      "7 : 67\n",
      "8 : 1\n",
      "9 : 34\n",
      "10 : 0\n",
      "11 : 1\n",
      "12 : 79\n",
      "13 : 0\n",
      "14 : 7\n",
      "15 : 2\n",
      "16 : 0\n",
      "17 : 9\n",
      "18 : 34\n",
      "711 = 711 711\n"
     ]
    }
   ],
   "source": [
    "comment_dict = {}\n",
    "tot_data = 0\n",
    "for idx1, item in enumerate(condensed_reddit_data):\n",
    "    for idx2, data in enumerate(item):\n",
    "        tot_data += 1\n",
    "        c_id = data['comment_id']\n",
    "        p_id = data['parent_id']\n",
    "        text = data['text']\n",
    "        created_date = get_calendar_date(data['created_utc'])\n",
    "        age = data['age']\n",
    "        comment_dict[c_id] = {'comment_id': c_id, 'parent_id': p_id, 'text': text, 'age': age, 'created': created_date}\n",
    "    print(idx1, ':', idx2)\n",
    "comment_dict_list = list(comment_dict.keys())\n",
    "print(len(comment_dict), '=', tot_data, len(comment_dict_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fcfc9de-4739-424b-a986-4313587d75f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_details(comm_id):\n",
    "    done = 0\n",
    "    data_details = []\n",
    "    while done==0:\n",
    "        if comm_id in comment_dict:\n",
    "            details = comment_dict[comm_id]\n",
    "            data_details.append(details)\n",
    "            comm_id = details['parent_id']\n",
    "        else:\n",
    "            done = 1\n",
    "    return data_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a36e7c-a913-4299-b5fb-8733457c8d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_lst = []\n",
    "old_comments = []\n",
    "age_limit = 3\n",
    "for idx, reddit_data_item in enumerate(condensed_reddit_data):\n",
    "    comment_lst = []\n",
    "    for idx2, comment_data in enumerate(reddit_data_item):\n",
    "        if comment_data['age'] < age_limit:\n",
    "            comm_id = comment_data['comment_id']  \n",
    "            comment_text = comment_data['text']\n",
    "            print(f'STARTING {idx} - {idx2} - {comm_id}')   \n",
    "            input_dict = {\"comment_id\": comm_id,\n",
    "                          \"input_data\": comment_text,\n",
    "                          \"product_long\": product_long,\n",
    "                          \"product_short\": product_short,\n",
    "                          \"domain\": domain,\n",
    "                          \"broad_keywords\": broad_keywords,\n",
    "                          \"output_format\":output_format_1, \n",
    "                          \"tip_text\":tip_text}\n",
    "            decision_result = response_creation_crew.kickoff(inputs=input_dict)\n",
    "            try:\n",
    "                json_out = ast.literal_eval(decision_result.json)\n",
    "            except:\n",
    "                print('Exception in json - trying re')\n",
    "                _, d, j = re_decision_string(decision_result.raw)            \n",
    "                json_out = {'comm_id': comm_id, 'decision': str(d), 'justification': str(j)}\n",
    "            comment_lst.append(json_out)\n",
    "        else:\n",
    "            old_comments.append(comment_data)\n",
    "    decision_lst.append(comment_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e8a5b374-3025-459c-8036-4e71e9a4c8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment key error : {'ku3v9wy': {'decision': 'discard', 'justification': 'Short message, less than 15 words.'}}\n",
      "comment key error : {'ku5l2mj': {'decision': 'relevant', 'justification': 'Seeks advice on skylight heat and shading.'}}\n",
      "Comment ID not found : kq75xk\n",
      "Comment ID not found : krct1qh\n",
      "Comment ID not found : krclyt\n",
      "comment key error : {'kcnf0d0': {'decision': 'discard', 'justification': 'Short message, less than 15 words.'}}\n",
      "comment key error : {'k34z5z8': {'decision': 'discard', 'justification': 'Very short message, less than 7 words.'}}\n",
      "Comment ID not found : iyawpm\n",
      "Comment ID not found : 1\n",
      "Comment ID not found : iyv709\n",
      "relevant : 71 discarded : 117 bad_cnt: 10 total: 198\n",
      "Old comments already filtered out : 513\n"
     ]
    }
   ],
   "source": [
    "decision_out = prep_decision_list(decision_lst, old_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dfeabba2-1293-405b-8470-0c34e3b753b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "117\n",
      "188\n",
      "513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'comment_id': 'ku4kjo6',\n",
       " 'decision': 'relevant',\n",
       " 'justification': \"The comment expresses a desire for practical kitchen design that is both beautiful and functional, aligning with CasaAI's scope.\"}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for item in decision_out:\n",
    "    print(len(item))\n",
    "content_filter_relevant, content_filter_discard, content_filter_analysis, content_filter_old = decision_out\n",
    "content_filter_relevant[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "92ece0fc-7d78-42e4-9f8a-72fa4443b6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files has been written\n",
      "Files Reloaded\n"
     ]
    }
   ],
   "source": [
    "with open('decision_result_v6_0901B.txt', \"w\") as file:\n",
    "    # Iterate through the list and write each string to the file\n",
    "    for item in content_filter_analysis:\n",
    "        file.write(item + \"\\n\")  # Add a newline character after each string\n",
    "with open('decision_old_v6_0901B.txt', \"w\") as file:\n",
    "    # Iterate through the list and write each string to the file\n",
    "    for item in content_filter_old:\n",
    "        file.write(item + \"\\n\")  # Add a newline character after each string\n",
    "\n",
    "print(f\"Files has been written\")\n",
    "\n",
    "with open('decision_result_v6_0901B.txt', \"r\") as file:\n",
    "    # Read all lines and strip the newline character from each line\n",
    "    analysis_lst_loaded_back = [line.strip() for line in file.readlines()]\n",
    "print(f\"Files Reloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1e0c33ee-a4f4-4ef0-853b-6b74f708177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "backstory = agent_cfg_data['content_scoring_analyst']['backstory'] \n",
    "goal = agent_cfg_data['content_scoring_analyst']['goal']\n",
    "role = agent_cfg_data['content_scoring_analyst']['role'] \n",
    "content_scoring_analyst = Agent(\n",
    "                            role=role,\n",
    "                            goal=goal,\n",
    "                            backstory=backstory,\n",
    "                            allow_delegation=False,\n",
    "                            verbose=False,\n",
    "                            llm=gemma2_9b,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "87f6bfbb-69f3-41af-968e-92741e883616",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreOutput(BaseModel):\n",
    "    comment_id: str\n",
    "    score: float\n",
    "    justification: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b359e7a1-ae2b-4786-996d-060055e7e6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = task_cfg_data['content_scoring_task']['description']\n",
    "expected_out = task_cfg_data['content_scoring_task']['expected_out'] \n",
    "        \n",
    "content_scoring_task = Task(\n",
    "                            description=description,\n",
    "                            expected_output=expected_out,\n",
    "                            output_json=ScoreOutput,\n",
    "                            agent=content_filter_analyst,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e53c7d07-94a9-4e8e-9433-28d811be8af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 11:00:31,862 - 140270313555776 - __init__.py-__init__:538 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "score_creation_crew = Crew(\n",
    "    agents=[content_scoring_analyst,],\n",
    "    tasks=[content_scoring_task,],\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269cc1ca-efad-4790-b6f9-53cd25bbc37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_result_lst = []\n",
    "for idx, comment_data in enumerate(content_filter_relevant):     \n",
    "    comm_id = comment_data['comment_id']        \n",
    "    print(f'STARTING {idx} - {comm_id}')\n",
    "    data_details = get_data_details(comm_id)      \n",
    "    input_dict = {\"comment_id\": comm_id,\n",
    "                  \"input_data\": data_details,\n",
    "                  \"product_long\": product_long,\n",
    "                  \"product_short\": product_short,\n",
    "                  \"domain\": domain,\n",
    "                  \"product_name\": product_name,\n",
    "                  \"tip_text\":tip_text}\n",
    "    scoring_result = score_creation_crew.kickoff(inputs=input_dict)\n",
    "    try:\n",
    "        json_out = ast.literal_eval(scoring_result.json)\n",
    "    except:\n",
    "        print('Exception in json - trying re')\n",
    "        _, s, j = re_score_string(scoring_result.raw)            \n",
    "        json_out = {'comm_id': comm_id, 'score': float(s), 'justification': str(j)}            \n",
    "    score_result_lst.append(json_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "40756e14-92ae-4ded-b4bd-c51a71fdaa74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'comment_id': 'ku4kjo6',\n",
       "  'score': 8.2,\n",
       "  'justification': \"Expresses desire for a usable kitchen, aligns with CasaAI's functionality.\"},\n",
       " 71,\n",
       " 71)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_result_lst[0], len(score_result_lst), len(relevant_json_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "74faf1af-15f0-4944-86fb-d35a0cbfa518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0 : 33 / 71\n",
      "7.5 : 28 / 71\n",
      "8.0 : 17 / 71\n",
      "8.5 : 12 / 71\n",
      "9.0 : 3 / 71\n",
      "9.5 : 0 / 71\n"
     ]
    }
   ],
   "source": [
    "thresh_list = [7.0, 7.5, 8.0, 8.5, 9.0, 9.5]\n",
    "\n",
    "for thresh in thresh_list:\n",
    "    thresh_up = 0\n",
    "    for item in score_result_lst:\n",
    "        if item['score'] >= thresh:\n",
    "            thresh_up += 1\n",
    "    print(thresh, ':', thresh_up, '/', len(score_result_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "13804a0e-c5ef-431d-a425-463f1063e1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevant : 71 bad_cnt: 0 total: 71\n",
      "71 71\n"
     ]
    }
   ],
   "source": [
    "score_out = prep_score_output(score_result_lst)\n",
    "content_score_good, content_score_bad, content_score_analysis = score_out\n",
    "print(len(content_score_good), len(content_score_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9cd143f0-52f0-41f3-af5c-b73976cb8413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been written\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "with open('score_result_v6_0901A.txt', \"w\") as file:\n",
    "    # Iterate through the list and write each string to the file\n",
    "    for item in content_score_analysis:\n",
    "        file.write(item + \"\\n\")  # Add a newline character after each string\n",
    "\n",
    "print(f\"File has been written\")\n",
    "\n",
    "with open('score_result_v6_0901A.txt', \"r\") as file:\n",
    "    # Read all lines and strip the newline character from each line\n",
    "    analysis_lst_loaded_back = [line.strip() for line in file.readlines()]\n",
    "print(len(analysis_lst_loaded_back))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0108e21e-4fa6-42a9-a86e-a76a5d695db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(filtered_comment_ids) : 33\n"
     ]
    }
   ],
   "source": [
    "# For each post-comment combo select the post-comments whose score >= 7\n",
    "filter_thresh = 7.0\n",
    "filtered_comment_ids = []\n",
    "for item in score_result_lst:\n",
    "    if item['score'] >= filter_thresh:\n",
    "        filtered_comment_ids.append(item['comment_id'])\n",
    "print(f'len(filtered_comment_ids) : {len(filtered_comment_ids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617f5dc2-690e-4048-bf91-4a067f985eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build response for these comments With Manager LLM + only 1 response writer + meta reviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "203302d6-24c3-4106-b859-9b44c1f39bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_writer = Agent(\n",
    "          role=\"Response writer\",\n",
    "          goal=\"Write the response to the comments in a casual way including marketing message of the {product} \",\n",
    "          backstory=\"You will be given json data of comments. These comments are coming from content filterer agent and\"\n",
    "                    \"is relevant to the product that we are marketing. Your job is to draft a casual reply to the comment \"\n",
    "                    \" which will sound genuine and inline with the general thread of discussion. You should also \"\n",
    "                    \" gently insert a short (within 25 words) marketing message of {product} in between in a natural way.\",\n",
    "          allow_delegation=True,\n",
    "          verbose=True,\n",
    "          llm=gemma2_9b\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "244fef72-e780-4825-a50e-33010b5f25bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_reviewer = Agent(\n",
    "\trole=\"Meta Reviewer\",\n",
    "\tgoal=\"You review the response crafted and provide suggestions to improve\",\n",
    "\tbackstory=(\n",
    "    \"You will receive the reply written by response writer agent. These replies are intended to market our {product} in the\"\n",
    "    \"guise of providing genuine suggestions/answers to the original comment.\"\n",
    "    \"Your goal is to review these replies to ensure that \"\n",
    "    \"message is interesting and marketing of product happens naturally while catching attention.\"\n",
    "\t),\n",
    "  allow_delegation=True,\n",
    "  verbose=True,\n",
    "  llm=gemma2_9b\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e2624857-d516-4cbe-b1ef-ccd1ad77ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_write_task = Task(\n",
    "    description=(\n",
    "        \"1. Comments you are getting as input are suggestions/advises to the help seeked in title or may be follow-up questions to understand the ask better.\\n\"\n",
    "        \"2. Read the comments from input and understand whether it is a suggestion/advise/follow-up question.\\n\"\n",
    "        \"3. Once done, draft text based on the type of comment.\\n\"\n",
    "        \"4. Reply should sound genuine and in-synch with the overall thread of discussion.\\n\"\n",
    "        \"5. Response style must be crisp, casual, friendly and must not include any reference to the product.\\n\"\n",
    "        \"6. Please include keywords mentioned in the original comment in your response text.\\n\"\n",
    "        \"7. Please be careful not to include keywords that were NOT mentioned in the original comment in your response text.\\n\"\n",
    "        \"8. Insert marketing text for the {product} in between these casual replies.\\n\"\n",
    "        \"9. Marketing text inserted must feel natural and in-synch and must not exceed 25 words.\\n\"\n",
    "        \"10. If needed, inlcude the link to the product website.\\n\"\n",
    "        \"11. Input data to be used is {input_data}.\\n\"\n",
    "        \"12. Response you drafted will be sent to meta reviewer for critic review.\\n\"\n",
    "        \"13. You have to refine the response based on review comments from meta reviewer and create the output.\\n\"\n",
    "        \"14. For output, include the 'Comment_id' and 'text' that you modified after review.\\n\"\n",
    "        \"15. You are the one responsible for providing final output after taking care of review comments.\\n\"\n",
    "        \"16. Please ensure that final output you are providing has reply for each comment provided in input_data.\\n\"\n",
    "    ),\n",
    "    expected_output=\"A json format of 'Comment_id':'response-text'\",\n",
    "    agent=response_writer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7a158911-3e16-4acc-8329-3894e231820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_review_task = Task(\n",
    "    description=(\n",
    "        \"1. You are getting the casual replies drafted by response writer agent.\\n\"\n",
    "        \"2. These casual replies also has marketing text inserted for the {product} in between.\\n\"\n",
    "        \"3. Review these casual replies considering below points:\\n\"\n",
    "            \"a. optimize content for search engines, ensuring that it ranks well and attracts organic traffic.\\n\"\n",
    "            \"b. marketing message is catchy and gets attention.\\n\"\n",
    "            \"c. There are no offensive words or content in the message.\\n\"\n",
    "        \"4. Make sure your suggestion is concise (within 3 bullet points), concrete and to the point.\\n\"\n",
    "        \"5. For output, include the 'Comment_id' and 'review_comment' .\\n\"\n",
    "        \"6. Your review comments will be taken care by response writer agent. \\n\"\n",
    "    ),\n",
    "    agent=meta_reviewer,\n",
    "    expected_output=\"A json format of 'Comment_id':'review_comment'\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "698d645e-df86-4961-9ecd-e83c82b57d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_llm = Ollama(model='gemma2:9b',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3f970d0e-a49e-4bf8-a024-f7ea62e8f537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 12:16:13,111 - 140270313555776 - __init__.py-__init__:538 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "response_creation_crew = Crew(\n",
    "    agents=[response_writer, meta_reviewer],\n",
    "    tasks=[response_write_task, meta_review_task, response_write_task],\n",
    "    verbose=True,\n",
    "    manager_llm=manager_llm,\n",
    "    process=Process.hierarchical\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6a2edb7c-de49-4c20-8eea-42ad62afaa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = response_creation_crew.kickoff(inputs={\"product\": casa_ai_descr, \"input_data\": comments_lst})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73231baa-813b-4bd6-b502-72bbbd21392f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
